{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV, GroupKFold\n",
    "\n",
    "import egoviz.models.processing as pr\n",
    "import egoviz.models.evaluation as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "file_path = os.path.join(cwd, '../data/home_data_all_preds_df.pkl')\n",
    "df = pr.load_pickle(file_path)\n",
    "df = pr.generate_counts_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into X and y and get groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['adl', 'video'], axis=1)\n",
    "y = df['adl']\n",
    "groups = df['video'].str[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'learning_rate': stats.uniform(0.01, 0.2 - 0.01),\n",
    "    'n_estimators': stats.randint(100, 301),\n",
    "    'max_depth': stats.randint(3, 6),\n",
    "    'subsample': stats.uniform(0.8, 1.0 - 0.8),\n",
    "    'colsample_bytree': stats.uniform(0.8, 1.0 - 0.8),\n",
    "    'min_child_weight': stats.randint(1, 11),\n",
    "    'gamma': stats.uniform(0, 0.2),\n",
    "    'scale_pos_weight': stats.randint(1, 6)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 16 folds for each of 10 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [23:32:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [23:32:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=GroupKFold(n_splits=16),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=&#x27;mlogloss&#x27;,\n",
       "                                           feature_types=None, gamma=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_co...\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000237606B94D0&gt;,\n",
       "                                        &#x27;scale_pos_weight&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000023770C46710&gt;,\n",
       "                                        &#x27;subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000023770BFADD0&gt;},\n",
       "                   random_state=42, return_train_score=True, scoring=&#x27;f1_macro&#x27;,\n",
       "                   verbose=999)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=GroupKFold(n_splits=16),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=&#x27;mlogloss&#x27;,\n",
       "                                           feature_types=None, gamma=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_co...\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000237606B94D0&gt;,\n",
       "                                        &#x27;scale_pos_weight&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000023770C46710&gt;,\n",
       "                                        &#x27;subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000023770BFADD0&gt;},\n",
       "                   random_state=42, return_train_score=True, scoring=&#x27;f1_macro&#x27;,\n",
       "                   verbose=999)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_class=7, num_parallel_tree=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_class=7, num_parallel_tree=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=GroupKFold(n_splits=16),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric='mlogloss',\n",
       "                                           feature_types=None, gamma=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_co...\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000237606B94D0>,\n",
       "                                        'scale_pos_weight': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000023770C46710>,\n",
       "                                        'subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000023770BFADD0>},\n",
       "                   random_state=42, return_train_score=True, scoring='f1_macro',\n",
       "                   verbose=999)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a GroupKFold object\n",
    "group_kfold = GroupKFold(n_splits=16)\n",
    "\n",
    "# Create an XGBClassifier object\n",
    "xgb_clf = XGBClassifier(objective='multi:softmax', num_class=len(set(y)), eval_metric='mlogloss', random_state=SEED, tree_method='gpu_hist')\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=xgb_clf, param_distributions=param_distributions, n_iter=10, scoring='f1_macro', cv=group_kfold, verbose=999, n_jobs=-1, return_train_score=True, random_state=SEED)\n",
    "random_search.fit(X, y_encoded, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.8650660661526529, 'gamma': 0.07773545793789641, 'learning_rate': 0.061556316037040225, 'max_depth': 3, 'min_child_weight': 8, 'n_estimators': 253, 'scale_pos_weight': 1, 'subsample': 0.8561869019374762}\n",
      "\n",
      "Results DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_scale_pos_weight</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>split15_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>split10_train_score</th>\n",
       "      <th>split11_train_score</th>\n",
       "      <th>split12_train_score</th>\n",
       "      <th>split13_train_score</th>\n",
       "      <th>split14_train_score</th>\n",
       "      <th>split15_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.533121</td>\n",
       "      <td>0.840663</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.020518</td>\n",
       "      <td>0.874908</td>\n",
       "      <td>0.190143</td>\n",
       "      <td>0.149079</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>202</td>\n",
       "      <td>2</td>\n",
       "      <td>0.831199</td>\n",
       "      <td>{'colsample_bytree': 0.8749080237694725, 'gamm...</td>\n",
       "      <td>0.511523</td>\n",
       "      <td>0.513767</td>\n",
       "      <td>0.245759</td>\n",
       "      <td>0.250283</td>\n",
       "      <td>0.437262</td>\n",
       "      <td>0.266657</td>\n",
       "      <td>0.489173</td>\n",
       "      <td>0.392235</td>\n",
       "      <td>0.437829</td>\n",
       "      <td>0.203223</td>\n",
       "      <td>0.512393</td>\n",
       "      <td>0.432484</td>\n",
       "      <td>0.266974</td>\n",
       "      <td>0.700073</td>\n",
       "      <td>0.292749</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.131215</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999519</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.999461</td>\n",
       "      <td>0.997518</td>\n",
       "      <td>0.998912</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>0.998026</td>\n",
       "      <td>0.998684</td>\n",
       "      <td>0.998282</td>\n",
       "      <td>0.999474</td>\n",
       "      <td>0.999467</td>\n",
       "      <td>0.998860</td>\n",
       "      <td>0.998887</td>\n",
       "      <td>0.998037</td>\n",
       "      <td>0.998953</td>\n",
       "      <td>0.998903</td>\n",
       "      <td>0.000621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.809638</td>\n",
       "      <td>1.587590</td>\n",
       "      <td>0.498915</td>\n",
       "      <td>0.013867</td>\n",
       "      <td>0.811617</td>\n",
       "      <td>0.173235</td>\n",
       "      <td>0.124212</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>{'colsample_bytree': 0.8116167224336399, 'gamm...</td>\n",
       "      <td>0.523727</td>\n",
       "      <td>0.461065</td>\n",
       "      <td>0.299549</td>\n",
       "      <td>0.238637</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.268636</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.299913</td>\n",
       "      <td>0.531633</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.450728</td>\n",
       "      <td>0.382894</td>\n",
       "      <td>0.266974</td>\n",
       "      <td>0.505613</td>\n",
       "      <td>0.319712</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.385528</td>\n",
       "      <td>0.098704</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999588</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.999582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>0.999599</td>\n",
       "      <td>0.999562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999608</td>\n",
       "      <td>0.999655</td>\n",
       "      <td>0.000460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.286115</td>\n",
       "      <td>0.284069</td>\n",
       "      <td>0.428894</td>\n",
       "      <td>0.011726</td>\n",
       "      <td>0.987711</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.19852</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>121</td>\n",
       "      <td>5</td>\n",
       "      <td>0.886389</td>\n",
       "      <td>{'colsample_bytree': 0.98771054180315, 'gamma'...</td>\n",
       "      <td>0.504702</td>\n",
       "      <td>0.507639</td>\n",
       "      <td>0.245360</td>\n",
       "      <td>0.261560</td>\n",
       "      <td>0.433270</td>\n",
       "      <td>0.258587</td>\n",
       "      <td>0.517107</td>\n",
       "      <td>0.351887</td>\n",
       "      <td>0.432667</td>\n",
       "      <td>0.199062</td>\n",
       "      <td>0.519138</td>\n",
       "      <td>0.364421</td>\n",
       "      <td>0.264932</td>\n",
       "      <td>0.667416</td>\n",
       "      <td>0.298955</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.385002</td>\n",
       "      <td>0.127592</td>\n",
       "      <td>8</td>\n",
       "      <td>0.987260</td>\n",
       "      <td>0.990112</td>\n",
       "      <td>0.975059</td>\n",
       "      <td>0.981076</td>\n",
       "      <td>0.985231</td>\n",
       "      <td>0.984713</td>\n",
       "      <td>0.985419</td>\n",
       "      <td>0.985901</td>\n",
       "      <td>0.988978</td>\n",
       "      <td>0.988278</td>\n",
       "      <td>0.983757</td>\n",
       "      <td>0.984279</td>\n",
       "      <td>0.986736</td>\n",
       "      <td>0.986745</td>\n",
       "      <td>0.983071</td>\n",
       "      <td>0.985278</td>\n",
       "      <td>0.985118</td>\n",
       "      <td>0.003399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116.453400</td>\n",
       "      <td>0.307399</td>\n",
       "      <td>0.721657</td>\n",
       "      <td>0.019460</td>\n",
       "      <td>0.858246</td>\n",
       "      <td>0.122371</td>\n",
       "      <td>0.036504</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>207</td>\n",
       "      <td>4</td>\n",
       "      <td>0.918483</td>\n",
       "      <td>{'colsample_bytree': 0.8582458280396084, 'gamm...</td>\n",
       "      <td>0.472142</td>\n",
       "      <td>0.506160</td>\n",
       "      <td>0.237438</td>\n",
       "      <td>0.265640</td>\n",
       "      <td>0.432557</td>\n",
       "      <td>0.259226</td>\n",
       "      <td>0.497614</td>\n",
       "      <td>0.300353</td>\n",
       "      <td>0.433954</td>\n",
       "      <td>0.289084</td>\n",
       "      <td>0.443449</td>\n",
       "      <td>0.404778</td>\n",
       "      <td>0.326641</td>\n",
       "      <td>0.713082</td>\n",
       "      <td>0.369860</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.392832</td>\n",
       "      <td>0.118477</td>\n",
       "      <td>5</td>\n",
       "      <td>0.988238</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>0.981762</td>\n",
       "      <td>0.988103</td>\n",
       "      <td>0.988612</td>\n",
       "      <td>0.991332</td>\n",
       "      <td>0.990945</td>\n",
       "      <td>0.988692</td>\n",
       "      <td>0.990220</td>\n",
       "      <td>0.989447</td>\n",
       "      <td>0.989418</td>\n",
       "      <td>0.987487</td>\n",
       "      <td>0.991831</td>\n",
       "      <td>0.987967</td>\n",
       "      <td>0.988368</td>\n",
       "      <td>0.988851</td>\n",
       "      <td>0.989117</td>\n",
       "      <td>0.002598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131.104339</td>\n",
       "      <td>0.326026</td>\n",
       "      <td>0.795803</td>\n",
       "      <td>0.039975</td>\n",
       "      <td>0.80929</td>\n",
       "      <td>0.121509</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993126</td>\n",
       "      <td>{'colsample_bytree': 0.8092900825439996, 'gamm...</td>\n",
       "      <td>0.470461</td>\n",
       "      <td>0.497658</td>\n",
       "      <td>0.238018</td>\n",
       "      <td>0.299457</td>\n",
       "      <td>0.405031</td>\n",
       "      <td>0.256414</td>\n",
       "      <td>0.510483</td>\n",
       "      <td>0.290491</td>\n",
       "      <td>0.518090</td>\n",
       "      <td>0.261703</td>\n",
       "      <td>0.450728</td>\n",
       "      <td>0.361936</td>\n",
       "      <td>0.320357</td>\n",
       "      <td>0.727513</td>\n",
       "      <td>0.345802</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.392967</td>\n",
       "      <td>0.125743</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997269</td>\n",
       "      <td>0.999461</td>\n",
       "      <td>0.998174</td>\n",
       "      <td>0.999354</td>\n",
       "      <td>0.998301</td>\n",
       "      <td>0.998191</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.998282</td>\n",
       "      <td>0.998282</td>\n",
       "      <td>0.997864</td>\n",
       "      <td>0.998860</td>\n",
       "      <td>0.998814</td>\n",
       "      <td>0.998956</td>\n",
       "      <td>0.998415</td>\n",
       "      <td>0.998692</td>\n",
       "      <td>0.000724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>151.702986</td>\n",
       "      <td>0.677643</td>\n",
       "      <td>0.901615</td>\n",
       "      <td>0.018407</td>\n",
       "      <td>0.961679</td>\n",
       "      <td>0.060923</td>\n",
       "      <td>0.028558</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>271</td>\n",
       "      <td>5</td>\n",
       "      <td>0.966639</td>\n",
       "      <td>{'colsample_bytree': 0.9616794696232922, 'gamm...</td>\n",
       "      <td>0.467532</td>\n",
       "      <td>0.496265</td>\n",
       "      <td>0.250112</td>\n",
       "      <td>0.263137</td>\n",
       "      <td>0.446551</td>\n",
       "      <td>0.254529</td>\n",
       "      <td>0.458001</td>\n",
       "      <td>0.362758</td>\n",
       "      <td>0.433954</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.443449</td>\n",
       "      <td>0.378159</td>\n",
       "      <td>0.332621</td>\n",
       "      <td>0.727513</td>\n",
       "      <td>0.333040</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.387289</td>\n",
       "      <td>0.122155</td>\n",
       "      <td>6</td>\n",
       "      <td>0.973893</td>\n",
       "      <td>0.979406</td>\n",
       "      <td>0.957319</td>\n",
       "      <td>0.970494</td>\n",
       "      <td>0.974866</td>\n",
       "      <td>0.976804</td>\n",
       "      <td>0.971600</td>\n",
       "      <td>0.971177</td>\n",
       "      <td>0.977487</td>\n",
       "      <td>0.973580</td>\n",
       "      <td>0.972121</td>\n",
       "      <td>0.972197</td>\n",
       "      <td>0.976698</td>\n",
       "      <td>0.972057</td>\n",
       "      <td>0.972108</td>\n",
       "      <td>0.973049</td>\n",
       "      <td>0.972803</td>\n",
       "      <td>0.004703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>77.092258</td>\n",
       "      <td>0.625873</td>\n",
       "      <td>0.536672</td>\n",
       "      <td>0.012083</td>\n",
       "      <td>0.834673</td>\n",
       "      <td>0.078212</td>\n",
       "      <td>0.044625</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>0.91354</td>\n",
       "      <td>{'colsample_bytree': 0.8346729307015545, 'gamm...</td>\n",
       "      <td>0.472257</td>\n",
       "      <td>0.479857</td>\n",
       "      <td>0.232710</td>\n",
       "      <td>0.227728</td>\n",
       "      <td>0.447139</td>\n",
       "      <td>0.254529</td>\n",
       "      <td>0.433336</td>\n",
       "      <td>0.349090</td>\n",
       "      <td>0.530800</td>\n",
       "      <td>0.207504</td>\n",
       "      <td>0.435856</td>\n",
       "      <td>0.387657</td>\n",
       "      <td>0.332621</td>\n",
       "      <td>0.713082</td>\n",
       "      <td>0.317783</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.384705</td>\n",
       "      <td>0.127958</td>\n",
       "      <td>9</td>\n",
       "      <td>0.954780</td>\n",
       "      <td>0.958889</td>\n",
       "      <td>0.914780</td>\n",
       "      <td>0.955854</td>\n",
       "      <td>0.955944</td>\n",
       "      <td>0.956164</td>\n",
       "      <td>0.954491</td>\n",
       "      <td>0.953582</td>\n",
       "      <td>0.955892</td>\n",
       "      <td>0.953445</td>\n",
       "      <td>0.953687</td>\n",
       "      <td>0.954148</td>\n",
       "      <td>0.958447</td>\n",
       "      <td>0.953785</td>\n",
       "      <td>0.952692</td>\n",
       "      <td>0.953120</td>\n",
       "      <td>0.952481</td>\n",
       "      <td>0.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56.310826</td>\n",
       "      <td>0.151367</td>\n",
       "      <td>0.390441</td>\n",
       "      <td>0.010277</td>\n",
       "      <td>0.806263</td>\n",
       "      <td>0.168457</td>\n",
       "      <td>0.095453</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>0.809045</td>\n",
       "      <td>{'colsample_bytree': 0.8062626584911118, 'gamm...</td>\n",
       "      <td>0.467353</td>\n",
       "      <td>0.503653</td>\n",
       "      <td>0.248823</td>\n",
       "      <td>0.225423</td>\n",
       "      <td>0.456115</td>\n",
       "      <td>0.269225</td>\n",
       "      <td>0.463541</td>\n",
       "      <td>0.355876</td>\n",
       "      <td>0.442942</td>\n",
       "      <td>0.222109</td>\n",
       "      <td>0.443449</td>\n",
       "      <td>0.344287</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.712357</td>\n",
       "      <td>0.333040</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.384262</td>\n",
       "      <td>0.122790</td>\n",
       "      <td>10</td>\n",
       "      <td>0.988234</td>\n",
       "      <td>0.989715</td>\n",
       "      <td>0.979016</td>\n",
       "      <td>0.983818</td>\n",
       "      <td>0.983401</td>\n",
       "      <td>0.986564</td>\n",
       "      <td>0.984370</td>\n",
       "      <td>0.985600</td>\n",
       "      <td>0.986743</td>\n",
       "      <td>0.985407</td>\n",
       "      <td>0.983469</td>\n",
       "      <td>0.984004</td>\n",
       "      <td>0.987669</td>\n",
       "      <td>0.982852</td>\n",
       "      <td>0.983577</td>\n",
       "      <td>0.983574</td>\n",
       "      <td>0.984876</td>\n",
       "      <td>0.002472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>109.652230</td>\n",
       "      <td>0.380135</td>\n",
       "      <td>0.680940</td>\n",
       "      <td>0.086593</td>\n",
       "      <td>0.865066</td>\n",
       "      <td>0.077735</td>\n",
       "      <td>0.061556</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>253</td>\n",
       "      <td>1</td>\n",
       "      <td>0.856187</td>\n",
       "      <td>{'colsample_bytree': 0.8650660661526529, 'gamm...</td>\n",
       "      <td>0.522056</td>\n",
       "      <td>0.506763</td>\n",
       "      <td>0.268461</td>\n",
       "      <td>0.230682</td>\n",
       "      <td>0.470087</td>\n",
       "      <td>0.250633</td>\n",
       "      <td>0.466020</td>\n",
       "      <td>0.337057</td>\n",
       "      <td>0.530076</td>\n",
       "      <td>0.199467</td>\n",
       "      <td>0.435856</td>\n",
       "      <td>0.439677</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.667416</td>\n",
       "      <td>0.319712</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.393998</td>\n",
       "      <td>0.126245</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975185</td>\n",
       "      <td>0.982713</td>\n",
       "      <td>0.957516</td>\n",
       "      <td>0.972402</td>\n",
       "      <td>0.975236</td>\n",
       "      <td>0.975355</td>\n",
       "      <td>0.973854</td>\n",
       "      <td>0.969350</td>\n",
       "      <td>0.975925</td>\n",
       "      <td>0.972193</td>\n",
       "      <td>0.969490</td>\n",
       "      <td>0.971359</td>\n",
       "      <td>0.973837</td>\n",
       "      <td>0.967081</td>\n",
       "      <td>0.969854</td>\n",
       "      <td>0.969672</td>\n",
       "      <td>0.971939</td>\n",
       "      <td>0.005164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70.891505</td>\n",
       "      <td>0.952807</td>\n",
       "      <td>0.200588</td>\n",
       "      <td>0.113431</td>\n",
       "      <td>0.908539</td>\n",
       "      <td>0.028185</td>\n",
       "      <td>0.162417</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>0.954449</td>\n",
       "      <td>{'colsample_bytree': 0.9085392166316497, 'gamm...</td>\n",
       "      <td>0.511545</td>\n",
       "      <td>0.490944</td>\n",
       "      <td>0.243260</td>\n",
       "      <td>0.268006</td>\n",
       "      <td>0.466982</td>\n",
       "      <td>0.259093</td>\n",
       "      <td>0.470640</td>\n",
       "      <td>0.338376</td>\n",
       "      <td>0.436252</td>\n",
       "      <td>0.342106</td>\n",
       "      <td>0.443449</td>\n",
       "      <td>0.358327</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.667416</td>\n",
       "      <td>0.284237</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.393060</td>\n",
       "      <td>0.109924</td>\n",
       "      <td>2</td>\n",
       "      <td>0.995477</td>\n",
       "      <td>0.996266</td>\n",
       "      <td>0.990757</td>\n",
       "      <td>0.987813</td>\n",
       "      <td>0.994096</td>\n",
       "      <td>0.993023</td>\n",
       "      <td>0.992989</td>\n",
       "      <td>0.991724</td>\n",
       "      <td>0.994146</td>\n",
       "      <td>0.993395</td>\n",
       "      <td>0.995545</td>\n",
       "      <td>0.993987</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>0.992272</td>\n",
       "      <td>0.993653</td>\n",
       "      <td>0.993235</td>\n",
       "      <td>0.002017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      86.533121      0.840663         0.657319        0.020518   \n",
       "1      77.809638      1.587590         0.498915        0.013867   \n",
       "2      53.286115      0.284069         0.428894        0.011726   \n",
       "3     116.453400      0.307399         0.721657        0.019460   \n",
       "4     131.104339      0.326026         0.795803        0.039975   \n",
       "5     151.702986      0.677643         0.901615        0.018407   \n",
       "6      77.092258      0.625873         0.536672        0.012083   \n",
       "7      56.310826      0.151367         0.390441        0.010277   \n",
       "8     109.652230      0.380135         0.680940        0.086593   \n",
       "9      70.891505      0.952807         0.200588        0.113431   \n",
       "\n",
       "  param_colsample_bytree param_gamma param_learning_rate param_max_depth  \\\n",
       "0               0.874908    0.190143            0.149079               3   \n",
       "1               0.811617    0.173235            0.124212               5   \n",
       "2               0.987711    0.000156             0.19852               3   \n",
       "3               0.858246    0.122371            0.036504               5   \n",
       "4                0.80929    0.121509              0.0424               5   \n",
       "5               0.961679    0.060923            0.028558               5   \n",
       "6               0.834673    0.078212            0.044625               4   \n",
       "7               0.806263    0.168457            0.095453               4   \n",
       "8               0.865066    0.077735            0.061556               3   \n",
       "9               0.908539    0.028185            0.162417               3   \n",
       "\n",
       "  param_min_child_weight param_n_estimators param_scale_pos_weight  \\\n",
       "0                      5                202                      2   \n",
       "1                      6                152                      2   \n",
       "2                     10                121                      5   \n",
       "3                      3                207                      4   \n",
       "4                      2                231                      1   \n",
       "5                      7                271                      5   \n",
       "6                      6                153                      2   \n",
       "7                      4                113                      4   \n",
       "8                      8                253                      1   \n",
       "9                      9                170                      1   \n",
       "\n",
       "  param_subsample                                             params  \\\n",
       "0        0.831199  {'colsample_bytree': 0.8749080237694725, 'gamm...   \n",
       "1          0.9444  {'colsample_bytree': 0.8116167224336399, 'gamm...   \n",
       "2        0.886389  {'colsample_bytree': 0.98771054180315, 'gamma'...   \n",
       "3        0.918483  {'colsample_bytree': 0.8582458280396084, 'gamm...   \n",
       "4        0.993126  {'colsample_bytree': 0.8092900825439996, 'gamm...   \n",
       "5        0.966639  {'colsample_bytree': 0.9616794696232922, 'gamm...   \n",
       "6         0.91354  {'colsample_bytree': 0.8346729307015545, 'gamm...   \n",
       "7        0.809045  {'colsample_bytree': 0.8062626584911118, 'gamm...   \n",
       "8        0.856187  {'colsample_bytree': 0.8650660661526529, 'gamm...   \n",
       "9        0.954449  {'colsample_bytree': 0.9085392166316497, 'gamm...   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.511523           0.513767           0.245759           0.250283   \n",
       "1           0.523727           0.461065           0.299549           0.238637   \n",
       "2           0.504702           0.507639           0.245360           0.261560   \n",
       "3           0.472142           0.506160           0.237438           0.265640   \n",
       "4           0.470461           0.497658           0.238018           0.299457   \n",
       "5           0.467532           0.496265           0.250112           0.263137   \n",
       "6           0.472257           0.479857           0.232710           0.227728   \n",
       "7           0.467353           0.503653           0.248823           0.225423   \n",
       "8           0.522056           0.506763           0.268461           0.230682   \n",
       "9           0.511545           0.490944           0.243260           0.268006   \n",
       "\n",
       "   split4_test_score  split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0           0.437262           0.266657           0.489173           0.392235   \n",
       "1           0.406504           0.268636           0.522388           0.299913   \n",
       "2           0.433270           0.258587           0.517107           0.351887   \n",
       "3           0.432557           0.259226           0.497614           0.300353   \n",
       "4           0.405031           0.256414           0.510483           0.290491   \n",
       "5           0.446551           0.254529           0.458001           0.362758   \n",
       "6           0.447139           0.254529           0.433336           0.349090   \n",
       "7           0.456115           0.269225           0.463541           0.355876   \n",
       "8           0.470087           0.250633           0.466020           0.337057   \n",
       "9           0.466982           0.259093           0.470640           0.338376   \n",
       "\n",
       "   split8_test_score  split9_test_score  split10_test_score  \\\n",
       "0           0.437829           0.203223            0.512393   \n",
       "1           0.531633           0.357143            0.450728   \n",
       "2           0.432667           0.199062            0.519138   \n",
       "3           0.433954           0.289084            0.443449   \n",
       "4           0.518090           0.261703            0.450728   \n",
       "5           0.433954           0.215664            0.443449   \n",
       "6           0.530800           0.207504            0.435856   \n",
       "7           0.442942           0.222109            0.443449   \n",
       "8           0.530076           0.199467            0.435856   \n",
       "9           0.436252           0.342106            0.443449   \n",
       "\n",
       "   split11_test_score  split12_test_score  split13_test_score  \\\n",
       "0            0.432484            0.266974            0.700073   \n",
       "1            0.382894            0.266974            0.505613   \n",
       "2            0.364421            0.264932            0.667416   \n",
       "3            0.404778            0.326641            0.713082   \n",
       "4            0.361936            0.320357            0.727513   \n",
       "5            0.378159            0.332621            0.727513   \n",
       "6            0.387657            0.332621            0.713082   \n",
       "7            0.344287            0.326667            0.712357   \n",
       "8            0.439677            0.326667            0.667416   \n",
       "9            0.358327            0.375000            0.667416   \n",
       "\n",
       "   split14_test_score  split15_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.292749            0.333333         0.392857        0.131215   \n",
       "1            0.319712            0.333333         0.385528        0.098704   \n",
       "2            0.298955            0.333333         0.385002        0.127592   \n",
       "3            0.369860            0.333333         0.392832        0.118477   \n",
       "4            0.345802            0.333333         0.392967        0.125743   \n",
       "5            0.333040            0.333333         0.387289        0.122155   \n",
       "6            0.317783            0.333333         0.384705        0.127958   \n",
       "7            0.333040            0.333333         0.384262        0.122790   \n",
       "8            0.319712            0.333333         0.393998        0.126245   \n",
       "9            0.284237            0.333333         0.393060        0.109924   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                4            0.999519            0.999596   \n",
       "1                7            0.999588            0.999596   \n",
       "2                8            0.987260            0.990112   \n",
       "3                5            0.988238            0.994595   \n",
       "4                3            1.000000            1.000000   \n",
       "5                6            0.973893            0.979406   \n",
       "6                9            0.954780            0.958889   \n",
       "7               10            0.988234            0.989715   \n",
       "8                1            0.975185            0.982713   \n",
       "9                2            0.995477            0.996266   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.999327            0.999461            0.997518   \n",
       "1            1.000000            0.998125            0.999582   \n",
       "2            0.975059            0.981076            0.985231   \n",
       "3            0.981762            0.988103            0.988612   \n",
       "4            0.997269            0.999461            0.998174   \n",
       "5            0.957319            0.970494            0.974866   \n",
       "6            0.914780            0.955854            0.955944   \n",
       "7            0.979016            0.983818            0.983401   \n",
       "8            0.957516            0.972402            0.975236   \n",
       "9            0.990757            0.987813            0.994096   \n",
       "\n",
       "   split5_train_score  split6_train_score  split7_train_score  \\\n",
       "0            0.998912            0.999452            0.998026   \n",
       "1            1.000000            1.000000            0.999237   \n",
       "2            0.984713            0.985419            0.985901   \n",
       "3            0.991332            0.990945            0.988692   \n",
       "4            0.999354            0.998301            0.998191   \n",
       "5            0.976804            0.971600            0.971177   \n",
       "6            0.956164            0.954491            0.953582   \n",
       "7            0.986564            0.984370            0.985600   \n",
       "8            0.975355            0.973854            0.969350   \n",
       "9            0.993023            0.992989            0.991724   \n",
       "\n",
       "   split8_train_score  split9_train_score  split10_train_score  \\\n",
       "0            0.998684            0.998282             0.999474   \n",
       "1            1.000000            1.000000             1.000000   \n",
       "2            0.988978            0.988278             0.983757   \n",
       "3            0.990220            0.989447             0.989418   \n",
       "4            0.998857            0.998282             0.998282   \n",
       "5            0.977487            0.973580             0.972121   \n",
       "6            0.955892            0.953445             0.953687   \n",
       "7            0.986743            0.985407             0.983469   \n",
       "8            0.975925            0.972193             0.969490   \n",
       "9            0.994146            0.993395             0.995545   \n",
       "\n",
       "   split11_train_score  split12_train_score  split13_train_score  \\\n",
       "0             0.999467             0.998860             0.998887   \n",
       "1             0.999579             0.999599             0.999562   \n",
       "2             0.984279             0.986736             0.986745   \n",
       "3             0.987487             0.991831             0.987967   \n",
       "4             0.997864             0.998860             0.998814   \n",
       "5             0.972197             0.976698             0.972057   \n",
       "6             0.954148             0.958447             0.953785   \n",
       "7             0.984004             0.987669             0.982852   \n",
       "8             0.971359             0.973837             0.967081   \n",
       "9             0.993987             0.994775             0.991837   \n",
       "\n",
       "   split14_train_score  split15_train_score  mean_train_score  std_train_score  \n",
       "0             0.998037             0.998953          0.998903         0.000621  \n",
       "1             1.000000             0.999608          0.999655         0.000460  \n",
       "2             0.983071             0.985278          0.985118         0.003399  \n",
       "3             0.988368             0.988851          0.989117         0.002598  \n",
       "4             0.998956             0.998415          0.998692         0.000724  \n",
       "5             0.972108             0.973049          0.972803         0.004703  \n",
       "6             0.952692             0.953120          0.952481         0.009888  \n",
       "7             0.983577             0.983574          0.984876         0.002472  \n",
       "8             0.969854             0.969672          0.971939         0.005164  \n",
       "9             0.992272             0.993653          0.993235         0.002017  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best parameters\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Get the results as a DataFrame\n",
    "results_df = pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Display the DataFrame of results\n",
    "print(\"\\nResults DataFrame:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8650660661526529,\n",
       " 'gamma': 0.07773545793789641,\n",
       " 'learning_rate': 0.061556316037040225,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 8,\n",
       " 'n_estimators': 253,\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 0.8561869019374762}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add best params to classifier\n",
    "xgb_clf.set_params(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "unique_classes = sorted(set(y))\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = dict(zip(unique_classes, compute_class_weight('balanced', classes=unique_classes, y=y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best params without scale_pos_weight\n",
    "best_params_no_scale_pos_weight = best_params.copy()\n",
    "del best_params_no_scale_pos_weight['scale_pos_weight']\n",
    "\n",
    "# add best params to classifier\n",
    "xgb_clf2 = XGBClassifier(objective='multi:softmax', num_class=len(unique_classes), eval_metric='mlogloss', random_state=SEED, tree_method='gpu_hist', scale_pos_weight=class_weights, **best_params_no_scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2023-11-18 02:26:43,856 - root - INFO - Training complete for XGBClassifier, group left out: SCI02\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2023-11-18 02:26:46,059 - root - INFO - Training complete for XGBClassifier, group left out: SCI03\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2023-11-18 02:26:48,272 - root - INFO - Training complete for XGBClassifier, group left out: SCI06\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2023-11-18 02:26:50,528 - root - INFO - Training complete for XGBClassifier, group left out: SCI08\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2023-11-18 02:26:52,755 - root - INFO - Training complete for XGBClassifier, group left out: SCI10\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2023-11-18 02:26:54,949 - root - INFO - Training complete for XGBClassifier, group left out: SCI11\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2023-11-18 02:26:57,149 - root - INFO - Training complete for XGBClassifier, group left out: SCI12\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2023-11-18 02:26:59,388 - root - INFO - Training complete for XGBClassifier, group left out: SCI13\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:26:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2023-11-18 02:27:01,637 - root - INFO - Training complete for XGBClassifier, group left out: SCI14\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2023-11-18 02:27:03,849 - root - INFO - Training complete for XGBClassifier, group left out: SCI15\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2023-11-18 02:27:06,059 - root - INFO - Training complete for XGBClassifier, group left out: SCI16\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2023-11-18 02:27:08,238 - root - INFO - Training complete for XGBClassifier, group left out: SCI17\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2023-11-18 02:27:10,463 - root - INFO - Training complete for XGBClassifier, group left out: SCI18\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2023-11-18 02:27:12,705 - root - INFO - Training complete for XGBClassifier, group left out: SCI19\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2023-11-18 02:27:14,910 - root - INFO - Training complete for XGBClassifier, group left out: SCI20\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2023-11-18 02:27:17,107 - root - INFO - Training complete for XGBClassifier, group left out: SCI21\n",
      "c:\\Users\\adesh\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\egovizml-XPfoP_XE-py3.11\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:27:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 02:27:17,267 - root - INFO - LOGOCV complete for XGBClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_left_out</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>mean_precision</th>\n",
       "      <th>mean_recall</th>\n",
       "      <th>mean_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCI02</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.858289</td>\n",
       "      <td>0.421745</td>\n",
       "      <td>0.435856</td>\n",
       "      <td>0.686472</td>\n",
       "      <td>0.559138</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.481498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCI03</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.510928</td>\n",
       "      <td>0.548916</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>0.686472</td>\n",
       "      <td>0.559138</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.481498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCI06</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>0.491051</td>\n",
       "      <td>0.241342</td>\n",
       "      <td>0.485181</td>\n",
       "      <td>0.686472</td>\n",
       "      <td>0.559138</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.481498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCI08</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.686472</td>\n",
       "      <td>0.559138</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.481498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCI10</td>\n",
       "      <td>0.518349</td>\n",
       "      <td>0.393991</td>\n",
       "      <td>0.787570</td>\n",
       "      <td>0.268461</td>\n",
       "      <td>0.686472</td>\n",
       "      <td>0.559138</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.481498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCI11</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>0.402035</td>\n",
       "      <td>0.388286</td>\n",
       "      <td>0.679205</td>\n",
       "      <td>0.686472</td>\n",
       "      <td>0.559138</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.481498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SCI12</td>\n",
       "      <td>0.640909</td>\n",
       "      <td>0.517595</td>\n",
       "      <td>0.566234</td>\n",
       "      <td>0.506763</td>\n",
       "      <td>0.686472</td>\n",
       "      <td>0.559138</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.481498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SCI13</td>\n",
       "      <td>0.706215</td>\n",
       "      <td>0.524200</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.337057</td>\n",
       "      <td>0.686472</td>\n",
       "      <td>0.559138</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.481498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SCI14</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.559737</td>\n",
       "      <td>0.581304</td>\n",
       "      <td>0.608877</td>\n",
       "      <td>0.686472</td>\n",
       "      <td>0.559138</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.481498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SCI15</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.570168</td>\n",
       "      <td>0.704252</td>\n",
       "      <td>0.730076</td>\n",
       "      <td>0.686472</td>\n",
       "      <td>0.559138</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.481498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SCI16</td>\n",
       "      <td>0.775610</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>0.814528</td>\n",
       "      <td>0.470087</td>\n",
       "      <td>0.686472</td>\n",
       "      <td>0.559138</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.481498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SCI17</td>\n",
       "      <td>0.921397</td>\n",
       "      <td>0.516168</td>\n",
       "      <td>0.951362</td>\n",
       "      <td>0.522056</td>\n",
       "      <td>0.686472</td>\n",
       "      <td>0.559138</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.481498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SCI18</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.535507</td>\n",
       "      <td>0.743452</td>\n",
       "      <td>0.439677</td>\n",
       "      <td>0.686472</td>\n",
       "      <td>0.559138</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.481498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SCI19</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.754412</td>\n",
       "      <td>0.464744</td>\n",
       "      <td>0.319712</td>\n",
       "      <td>0.686472</td>\n",
       "      <td>0.559138</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.481498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SCI20</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.667416</td>\n",
       "      <td>0.686472</td>\n",
       "      <td>0.559138</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.481498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SCI21</td>\n",
       "      <td>0.402778</td>\n",
       "      <td>0.386243</td>\n",
       "      <td>0.581737</td>\n",
       "      <td>0.373540</td>\n",
       "      <td>0.686472</td>\n",
       "      <td>0.559138</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.481498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_left_out  accuracy  precision    recall        f1  mean_accuracy  \\\n",
       "0           SCI02  0.895833   0.858289  0.421745  0.435856       0.686472   \n",
       "1           SCI03  0.765625   0.510928  0.548916  0.526667       0.686472   \n",
       "2           SCI06  0.621359   0.491051  0.241342  0.485181       0.686472   \n",
       "3           SCI08  0.571429   0.666667  0.666667  0.333333       0.686472   \n",
       "4           SCI10  0.518349   0.393991  0.787570  0.268461       0.686472   \n",
       "5           SCI11  0.747475   0.402035  0.388286  0.679205       0.686472   \n",
       "6           SCI12  0.640909   0.517595  0.566234  0.506763       0.686472   \n",
       "7           SCI13  0.706215   0.524200  0.738272  0.337057       0.686472   \n",
       "8           SCI14  0.625000   0.559737  0.581304  0.608877       0.686472   \n",
       "9           SCI15  0.894118   0.570168  0.704252  0.730076       0.686472   \n",
       "10          SCI16  0.775610   0.570328  0.814528  0.470087       0.686472   \n",
       "11          SCI17  0.921397   0.516168  0.951362  0.522056       0.686472   \n",
       "12          SCI18  0.805970   0.535507  0.743452  0.439677       0.686472   \n",
       "13          SCI19  0.367347   0.754412  0.464744  0.319712       0.686472   \n",
       "14          SCI20  0.724138   0.688889  0.843137  0.667416       0.686472   \n",
       "15          SCI21  0.402778   0.386243  0.581737  0.373540       0.686472   \n",
       "\n",
       "    mean_precision  mean_recall   mean_f1  \n",
       "0         0.559138     0.627722  0.481498  \n",
       "1         0.559138     0.627722  0.481498  \n",
       "2         0.559138     0.627722  0.481498  \n",
       "3         0.559138     0.627722  0.481498  \n",
       "4         0.559138     0.627722  0.481498  \n",
       "5         0.559138     0.627722  0.481498  \n",
       "6         0.559138     0.627722  0.481498  \n",
       "7         0.559138     0.627722  0.481498  \n",
       "8         0.559138     0.627722  0.481498  \n",
       "9         0.559138     0.627722  0.481498  \n",
       "10        0.559138     0.627722  0.481498  \n",
       "11        0.559138     0.627722  0.481498  \n",
       "12        0.559138     0.627722  0.481498  \n",
       "13        0.559138     0.627722  0.481498  \n",
       "14        0.559138     0.627722  0.481498  \n",
       "15        0.559138     0.627722  0.481498  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_active = ev.leave_one_group_out_cv(df, X, y_encoded, groups, xgb_clf2, xgb=True)\n",
    "print('XGBoost Classifier')\n",
    "xgb_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egovizml-XPfoP_XE-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
